# 概率论

> 概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。

## 期望

对于一个连续型随机变量 $x$ ，其概率密度为 $f(x)$，则 $ X $ 的数学期望为：

$$
E(X)=\int_{\boldsymbol{x}}xf(x)dx
$$

如果另一个随机变量 $Y$ 符合 $ Y=g(x) $ （$g$ 连续），其概率密度函数为 $f(x)$，$ Y $ 的数学期望为:
$$
E(Y)=\int_{\boldsymbol{x}}g(x)f(x)dx
$$
即其概率密度函数（某点处概率值构成的函数）与其概率的乘积的积分。

对于一个离散型随机变量 $ P(X=x_k) = p_k $ , $ k=1, 2, ... , n $，数学期望为:
$$
E(X)=\sum_{k=1}^{n} x_kp_k
$$

同样地，对于另一个离散型随机变量 $Y$ 符合 $ Y=g(x) $ （$g$ 连续），其数学期望为：
$$
E(Y)=\sum_{k=1}^{n} g(x)p_k
$$

## 条件概率

$$
P(B\mid A) = \frac{P(BA)}{P(A)}
$$

其中，$A$ 与 $B$ 是样本空间上的两个事件，$ P(B\mid A) $ 是在 $A$ 发生的条件下，发生 $B$ 的概率，表示为联合概率分布$  P(BA) $ 与 $ P(A) $ 的商。

换个形式，通过条件概率 $P(B\mid A)$ 与先验概率 $ P(A) $ 我们就可以得到联合概率，这个公式又被称为乘法定理：

$$
P(BA) = P(B \mid A){P(A)}
$$

然后可以写出链式法则：
$$
P(ABCD)=P(DCBA) = P(D \mid CBA)P(C \mid BA)P(B\mid A)P(A)
$$

## 贝叶斯决策理论

对于参数估计，贝叶斯学派认为参数是未观察到的随机变量，其本身也可有分布，因此，可假定参数服从一个先验分布，然后基于观察到的数据来计算参数的后验分布。

贝叶斯法则是条件概率计算的重要依据：
$$
P(B\mid A)=\frac{P(AB)}{P(A)}=\frac{P(A\mid B) P(B)}{P(A)}
$$

结合全概率公式，将这个法则拓展到整个概率空间 $ \Omega $ 中，$ B_1, B_2, B_3, \ldots B_n $ 为 $ \Omega $ 的一个划分，贝叶斯法则可以泛化为：

$$
P\left(B_{j} \mid A\right)=\frac{P\left(A \mid B_{j}\right) P\left(B_{j}\right)}{P(A)}=\frac{P\left(A \mid B_{j}\right) P\left(B_{j}\right)}{\sum_{i=1}^{n} P\left(A \mid B_{i}\right) P\left(B_{i}\right)}
$$

在一个分类的机器学习任务中，定义一个样本为 $x$，有$ N$ 种可能的类别标记：$ Y=\{c_1, c_2, ... , c_N\} $ ，模型参数 $ \theta $。

$ P(\bold{c} \mid x) $ 就成为了**一个对单个样本进行各类概率评估的过程**。
$$
P(\bold{c}\mid x)=\frac{P(x\mid \bold{c}) P(\bold{c})}{P(x)}
$$
$P(x)$ 是样本 $x$ 出现的概率，显然对于一个给定的样本 $x$，这个值是固定的。因此不论对于最小化风险还是最小化错误率的贝叶斯决策模型，整个问题就变成了我们如何训练模型，完成对 $P(x \mid \bold{c})$ 和  $P(\bold{c})$ 的估计。

$P(\bold{c})$ 被称为**先验概率**，根据大数定律，我们可以在数据中疯狂抽样，然后将抽得的各类的样本数除以总抽样数就可以拟合$P(\bold{c})$ 。 

而 $P(x \mid \bold{c})$ 被称为**似然函数**，或者**类条件概率**，这是一个看起来很抽象的表达：
在已知参数的条件下，对样本进行估计。但是我们可以知道的是，它是 $P(\bold{c \mid x})$ 的逆过程，那很简单了，它就是一个**反向更新参数的过程**。

至于怎么求解 $ P(x \mid \bold{c}) $，看下一节。


## 极大似然估计

极大（最大）似然估计 (Maximum Likelihood Estimate, MLE)，就是用已知的样本结果信息，估计一个**确定形式**的模型的参数。

什么是估计确定形式的模型？比如我们认定一个正态分布可以较好的拟合这些样本信息，那我们就去估计其期望和方差连个参数。复杂一点，如果我们认为一个神经网络模型可以很好的拟合这个样本的分布，那就去估计该神经网络的模型参数 （$W$, $b$ 等）。

为了明确起见，我们把 $P(x \mid \bold{c})$ 记为 $ P(x \mid \theta_c) $。

比如我们要估计一个神经网络的参数，该神经网络在训练集 $D_c$ 上训练：

首先明确似然函数：

$$
P(x \mid \theta_c) = \prod_{x \in D_c} P(x \mid \theta_c)
$$

也就是，我们需要找到能最大化似然的函数值 $ \hat{\theta}_c$。极大似然估计也就是在所有可能的取值中，找到一个能使数据出现可能性最大的值。

然后我们对其取对数，为什么进行这一个步骤，主要有三个原因：

1. 原似然函数是连乘模式，整个值容易变得很小，造成下溢
2. 乘法计算复杂度远比加法高，取对数可以将乘法转化为加法，降低计算复杂度
3. 最基本地，取对数不影响单调性

然后我们得到对数似然 (Log Likelihood)：

$$
LL(\theta_{c}) = \sum_{x \in D_c} log(P(x \mid \theta_c))
$$

如果我们在做一个分类问题，此时分类标签 $ y $ 是一个 one-hot 向量，想一下当前模型的输出概率 $ P(c \mid x) $，我们容易发现 $ P(x\mid \theta_c) = P(c \mid x)^y $。

具体地，举个例子，在一个四分类问题中， $ P(c \mid x) = [0.1, 0.2, 0.6, 0.1] $，$ y = [0, 0, 1, 0] $，模型对当前标签的拟合优度就可以用 $P(x \mid \theta_c) = 0.1^{0}0.2^{0}0.6^{1}0.1^{0}=0.6$，我们当然希望调整参数，对于所有样本，使这个值的乘积或者加和越大越好。换一种角度来想，也是预测出的概率分布与 one-hot 分布越接近越好。

此时我们就需要求：
$$
\hat{\theta}_c = \operatorname{argmax}LL(\theta_{c})
$$

计算机更喜欢最小化问题，那就给它加个负号：

$$
\hat{\theta}_c = -\operatorname{argmin}LL(\theta_{c})
$$

将 $ P(x\mid \theta_c) = P(c \mid x)^y $ 代入 $ LL(\theta_{c}) $，得到：

$$
LL(\theta_{c}) = \sum_{x \in D_c} ylog(P(c \mid x))
$$

$$
\text{Cost}(\theta_c) = -\sum_{x \in D_c} ylog(P(c \mid x))
$$


**我们很神奇地发现，这就是多分类条件下的交叉熵啊！**这样我们就完成了一个从极大似然估计的角度理解交叉熵的过程。

类似地，我们用极大似然估计补全交叉熵的另一种形式：

在一个二分类问题中， $ P(c \mid x) = [0.4] $，$y=[0]$，直觉告诉我们，这个模型对于这个样本的拟合优度是 0.6，从数学上来看，它就是 $ P(c \mid x)^y(1-P(c\mid x))^{1-y} $，代入对数似然，我们得到：

$$
LL(\theta_{c}) = \sum_{x \in D_c} (ylog(P(c \mid x))+(1-y)log(1-P(c \mid x)))
$$

$$
\text{Cost}(\theta_{c}) = -\sum_{x \in D_c} (ylog(P(c \mid x))-(1-y)log(1-P(c \mid x)))
$$

也符合二分类下的交叉熵形式。

至于怎么去估计 $\hat{\theta}_c$ ，或者是求 Cost，那就是一个求导数 / 偏导数的问题了。

$$
\theta_c=\left[\theta_{1}, \theta_{2}, \cdots, \theta_{S}\right]^{T}
$$

$$
\nabla_{\theta} LL(\theta)=\sum_{x \in D_c} \nabla_{\theta} \log P\left(x \mid \theta\right)=0
$$

但是注意，这里一次性同时使用了全部的样本进行估计，找到了一个极大值点，作为参数的最优拟合。但在实际应用里，这样往往会导致显存和内存的爆炸，所以才会有随机梯度下降之类的慢慢优化的方法。

## 参考

《机器学习》 周志华

《统计自然语言处理》 宗成庆

https://blog.csdn.net/u011508640/article/details/72815981

https://zhuanlan.zhihu.com/p/26614750

https://zhuanlan.zhihu.com/p/73635902

https://blog.csdn.net/Mr_health/article/details/107625454
