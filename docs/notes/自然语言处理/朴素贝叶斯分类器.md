# 朴素贝叶斯分类器

朴素贝叶斯的基础是贝叶斯决策分类决策理论，根据贝叶斯决策分类决策理论，在自然语言处理中，假设我们需要对句子 $s=\{w_1,w_2,\ldots,w_n\}$ 在类别集 $C$ 上进行分类，$c$ 为类别标签，后验概率 $P(c\mid s)$ 即被定义为：
$$
P(c\mid s)=\frac{P(s\mid c) P(c)}{P(s)}
$$
为何称之为朴素呢？因为其采用了一个非常朴(Jian)素(Dan)的假设：所有特征的取值都是条件独立的。在句子分类器中，即整句句子的条件概率是句子中所有词的条件概率的连乘积：
$$
P(s\mid c)=P(w_1\mid c)P(w_2\mid c)\ldots P(w_n\mid c)
$$
在这个假设下，朴素贝叶斯分类器也就是：
$$
P(c \mid s) \propto P(d \mid c) P(c) \approx \prod_{i} P\left(w_{i} \mid c\right) P(c)
$$
因此，模型参数就是 $P(d \mid c)$ 与 $P(c)$ 两种，参数量为$|V|\times |C|+|C|$，$V$ 为词表。

## 训练

给定训练数据集 $D=\left.\left\{\left(s_{i}, c_{i}\right)\right\}\right|_{i=1} ^{N}$，先验 $P(c)$ 即类别为 $c$ 的标签在总数据集中的占比：
$$
P(c)=\frac{\bold c \in D}{\sum_{c^{\prime}}\left(\# c^{\prime} \in D\right)}=\frac{\# c \in D}{|D|}
$$
对于每个 $w$ 与 $c$ 二元组，$P(\bold w \mid c)$ 可以用极大似然估计进行计算：
$$
P(\mathbf{w} \mid c)=\frac{\#(\mathbf{w}, c) \in D}{\sum_{\mathbf{w}^{\prime}}\left(\#\left(\mathbf{w}^{\prime}, c\right) \in D\right)}
$$
其中分母为整个数据集中类别标签为 $c$ 的所有词的总个数。

## 推理

给定测试数据 $s$，预测类类别 $\hat{c}$ 为：
$$
\begin{aligned}
\hat{c} &=\arg \max _{c \in C} P(c \mid s) \\
&=\arg \max _{c \in C} \frac{P(s \mid c) P(c)}{P(s)}=\arg \max _{c \in C} P(s \mid c) P(c) \\
&=\arg \max _{c \in C} P(c) P\left(w_{1} \mid c\right) P\left(w_{2} \mid c\right) \ldots P\left(w_{n} \mid c\right)
\end{aligned}
$$

## 参考

WestlakeNLP《自然语言处理在线课程》