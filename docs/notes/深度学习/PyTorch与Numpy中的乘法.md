# PyTorch ä¸ Numpy ä¸­çš„ä¹˜æ³•

ä¹˜æ³•è¿ç®—æ˜¯ ML / DL ä¸­æœ€ä¸ºåŸºç¡€çš„è¿ç®—ä¹‹ä¸€ï¼Œä¸¤å¤§åŸºç¡€æ¡†æ¶ PyTorch ä¸ Numpy æä¾›äº†ç§ç±»ç¹å¤šçš„å‡½æ•°ï¼Œç„¶è€Œç”±äºä¸­è‹±æ–‡æ¦‚å¿µä¹‹é—´çš„å·®å¼‚ï¼Œæ¡†æ¶å®ç°ä¹‹é—´çš„å·®å¼‚ï¼Œå¯¼è‡´äº†ä½¿ç”¨æ—¶ææ˜“æ··æ·†ï¼Œå¾€å¾€å¯¼è‡´äº†è¿ç®—ç»“æœå‡ºé”™æˆ–è€…å‡ºç°ç»´åº¦ä¸åŒ¹é…çš„æƒ…å†µã€‚

##  æ•°å­¦æ¦‚å¿µ

### ç‚¹ç§¯ / å†…ç§¯ / æ•°é‡ç§¯ / å…ƒç´ ç§¯ (dot product)

ä¸€èˆ¬åœ°ï¼Œå¯¹äºç©ºé—´ä¸­çš„ä¸¤ä¸ª n ç»´å‘é‡ $\vec{a}, \vec{b}$  å…¶å†…ç§¯çš„ä»£æ•°å®šä¹‰å¦‚ä¸‹ï¼š
$$
a\cdot b = \sum\nolimits_{i=1}^{n}a_ib_i
$$

ä¸¤ä¸ªå‘é‡å†…ç§¯çš„ç»“æœæ˜¯ä¸ª**æ ‡é‡**ã€‚

### çŸ©é˜µä¹˜ç§¯ (matmul product)

æ•°å­¦æ„ä¹‰ä¸Šï¼ŒçŸ©é˜µä¹˜ç§¯ä»…åœ¨ç¬¬ä¸€ä¸ªçŸ©é˜µçš„åˆ—æ•° (column) å’Œç¬¬äºŒä¸ªçŸ©é˜µçš„è¡Œæ•° (row) ç›¸åŒæ—¶æ‰æœ‰æ„ä¹‰ï¼›

è®¾ $A$ æ˜¯å½¢çŠ¶ä¸º $m \times p$ çš„çŸ©é˜µï¼Œ$ B $ æ˜¯å½¢çŠ¶ä¸º $ p \times n$ çš„çŸ©é˜µï¼Œåˆ™çŸ©é˜µä¹˜ç§¯ $AB$ ç¬¬ $i$ è¡Œç¬¬ $j$ åˆ—çš„å…ƒç´ ä¸ºï¼š
$$
(AB)_{ij} = \sum\nolimits_{k=1}^{p}a_{ik}b_{kj}
$$

> ä¸¤ä¸ªç›¸åŒç»´æ•°çš„å‘é‡ $x$ å’Œ $y$ çš„ç‚¹ç§¯å¯çœ‹ä½œæ˜¯çŸ©é˜µä¹˜ç§¯ $x^\mathrm{T}y$ã€‚

### çŸ©é˜µå…ƒç´ ç§¯ (element-wise product / Hadamard product)

çŸ©é˜µ $A$ ä¸çŸ©é˜µ $B$ å¿…é¡»æ‹¥æœ‰ç›¸åŒçš„å½¢çŠ¶ï¼Œç±»ä¼¼åœ°çŸ©é˜µå…ƒç´ ç§¯ $A*B$ ç¬¬ $i$ è¡Œç¬¬ $j$ åˆ—çš„å…ƒç´ ä¸ºï¼š
$$
(A*B)_{ij} = a_{ij}b_{ij}
$$

## å¹¿æ’­æœºåˆ¶

ä»‹ç»ä¹˜æ³•ä¹‹å‰ï¼Œé¦–å…ˆåº”è¯¥ç†Ÿæ‚‰ PyTorch ä¸ Numpy ä¸­éƒ½å­˜åœ¨çš„å¹¿æ’­æœºåˆ¶ã€‚

é€šå¸¸åªåœ¨å¯¹å¤šä¸ªå¼ é‡è¿›è¡Œå¯¹åº”å…ƒç´ æ“ä½œå½¢çŠ¶ä¸åŒæ—¶ï¼Œä¼šå‘ç”Ÿå¹¿æ’­ã€‚å¹¿æ’­æœºåˆ¶å¯ä»¥æ˜¾è‘—å‡å°‘ä¸æ‹·è´å¼ é‡æœ‰å…³çš„ä»£ç ï¼Œä½¿ç®—æ³•å®ç°æ›´é«˜æ•ˆã€‚

Numpy ä¸­å¯¹äºå¹¿æ’­çš„å®˜æ–¹è§£é‡Šï¼š

> å°†ä¸¤ä¸ªå¼ é‡çš„å½¢çŠ¶ (shape) å°¾å¯¹å°¾å¯¹é½ï¼Œä»æœ€å°¾ç«¯çš„ç»´åº¦å‘å‰æ£€æŸ¥ï¼Œæ»¡è¶³ä»¥ä¸‹ä¸¤ä¸ªæ¡ä»¶ä¹‹ä¸€ï¼Œå¹¿æ’­å³å¯è¿›è¡Œï¼š
>
> 1. ä¸¤ä¸ªå¼ é‡åœ¨è¯¥ç»´åº¦çš„å¤§å°ç›¸ç­‰
> 2. ä¸¤ä¸ªå¼ é‡åœ¨è¯¥ç»´åº¦æœ‰ä¸€ä¸ªå¤§å°ä¸º1

æ›´ç›´æ¥åœ°ï¼Œå¯ä»¥ä¸¾å‡ ä¸ªä¾‹å­ï¼š

```
shape(8,1,6,1)
  shape(7,1,5) 
--------------
shape(8,7,6,5) // å¹¿æ’­ç»“æœ
==============
shape(3,3)
shape(3,1)
----------
shape(3,3) // å¹¿æ’­ç»“æœ
==========
shape(4,3)
  shape(4) 
----------
ValueError('frames are not aligned') // ä¸èƒ½è¿›è¡Œå¹¿æ’­ï¼Œä»å°¾éƒ¨å¼€å§‹ç¬¬ä¸€ä¸ªç»´åº¦å°±ä¸ç¬¦åˆä»»æ„ä¸€ä¸ªå¹¿æ’­æ¡ä»¶
```

ä»ä»£ç å±‚é¢ç†è§£ï¼Œä¸ä¸Šé¢ä¸¤æ¡è§„åˆ™å¯¹åº”åœ°ï¼Œä¸»è¦å¯ä»¥å‡å°‘ä»¥ä¸‹ä¸¤ç§æƒ…å†µçš„ä»£ç ï¼š

1. å¢åŠ ä¸€ä¸ªç©ºç»´åº¦ï¼Œå¦‚ ```x[:, np.newaxis]``` æˆ– ```np.expand_dims()```
2. æ²¿ä¸€ä¸ªå·²æœ‰çš„ç»´åº¦è¿›è¡Œå¼ é‡å †å ï¼Œå¦‚ ```np.tile()```

PyTorch çš„å¹¿æ’­æœºåˆ¶ä¸ Numpy ä¸€è‡´ã€‚

## * è¿ç®—ç¬¦

åœ¨ Numpy å’Œ PyTorch ä¸­ * è¿ç®—ç¬¦éƒ½ä»£è¡¨å¼ é‡**ç‚¹ç§¯**ï¼Œåˆ†åˆ«ä¸ ```np.multiply()``` ä¸ ```torch.mul()```ç­‰ä»·ã€‚

## @ è¿ç®—ç¬¦

åœ¨ Numpy å’Œ PyTorch ä¸­ @ è¿ç®—ç¬¦éƒ½ä»£è¡¨å¼ é‡**ä¹˜**ï¼Œåˆ†åˆ«ä¸ ```np.matmul()``` ä¸ ```torch.matmul()```ç­‰ä»·ã€‚

## dot

> torch.dot(input, other, *, out=None) â†’ Tensor

Pytorch ä¸­çš„ dot åªæ”¯æŒä¸¤ä¸ª**ä¸€ç»´å¼ é‡**ä¹‹é—´çš„è¿ç®—ï¼Œå¹¶ä¸”è¿™ä¸¤ä¸ªä¸€ç»´å¼ é‡æ‰€å«å…ƒç´ ä¸ªæ•°å¿…é¡»ç›¸åŒã€‚è¯¥è¿ç®—ä¸æ•°å­¦æ„ä¹‰ä¸Šçš„ç‚¹ç§¯å®Œå…¨ä¸€è‡´ã€‚

```python
>>> torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))
tensor(7)
```
> numpy.dot(a, b, out=None)

1. å½“ä¸¤ä¸ªå¾…è¿ç®—å¼ é‡éƒ½æ˜¯**ä¸€ç»´å¼ é‡**æ—¶ï¼ŒNumpy ä¸­çš„ dot ä¸ torch ä¸­çš„ dot ç­‰ä»·ã€‚

2. å½“ä¸¤ä¸ªå¾…è¿ç®—å¼ é‡éƒ½æ˜¯**äºŒç»´å¼ é‡**æ—¶ï¼ŒNumpy ä¸­çš„ dot å³ä¸ºçŸ©é˜µä¹˜ç§¯ã€‚
3. å½“ä¸¤ä¸ªå¾…è¿ç®—å¼ é‡éƒ½æ˜¯**é›¶ç»´å¼ é‡**ï¼ˆæ ‡é‡ï¼‰æ—¶ï¼ŒNumpy ä¸­çš„ dot å³ä¸ºæ™®é€šä¹˜æ³•ã€‚

å½“ä¸¤ä¸ªå¾…è¿ç®—å¼ é‡ç»´åº¦ä¸åŒ¹é…æ—¶ï¼ŒNumpy å°†è‡ªåŠ¨è¿›è¡Œåœ¨å¤šå‡ºç»´åº¦ä¸Šæ±‚å’Œè¿ç®—ï¼Œæ‰€ä»¥ï¼ŒNumpy çš„ dot å¹¶ä¸å®Œå…¨æ˜¯æ•°å­¦æ„ä¹‰ä¸Šçš„ç‚¹ç§¯è¿ç®—ï¼Œåœ¨å…¶å®é™…å®ç°æ„ä¹‰å’Œæ•°å­¦æ„ä¹‰ä¸ç›¸ç¬¦æ—¶ï¼Œåº”è¯¥è°¨æ…ä½¿ç”¨ã€‚

## matmul

> torch.matmul(*input*, *other*, ***, *out=None*) â†’ Tensor

è™½ç„¶åä¹‰ä¸Šæ˜¯ matmulï¼ˆçŸ©é˜µä¹˜ï¼‰å‡½æ•°ï¼Œä½†æ˜¯ PyTorch ä¾ç„¶åšäº†å…¨é¢çš„æ‰©å……ï¼Œä»¥è‡³äºå®˜æ–¹æ–‡æ¡£ä¸­æ•´ä¸ªå‡½æ•°çš„è§£é‡Šè¯´æ˜éå¸¸å¤æ‚ï¼Œè¿˜æ˜¯çœ‹å®é™…ä¾‹å­æ¯”è¾ƒå¥½äº›ï¼š

```python
>>> # vector x vector
>>> tensor1 = torch.randn(3)
>>> tensor2 = torch.randn(3)
>>> torch.matmul(tensor1, tensor2).size()
torch.Size([])
```

å½“ä¸¤ä¸ªè¾“å…¥å¼ é‡éƒ½æ˜¯å‘é‡æ—¶ matmul() æ‰§è¡Œ dot product æ“ä½œğŸ˜¶

```
>>> # matrix x vector
>>> tensor1 = torch.randn(3, 4)
>>> tensor2 = torch.randn(4)
>>> torch.matmul(tensor1, tensor2).size()
torch.Size([3])
```

å½“ä¸¤ä¸ªè¾“å…¥å¼ é‡åˆ†åˆ«ä¸ºçŸ©é˜µå’Œå‘é‡æ—¶ï¼Œæ‰§è¡ŒçŸ©é˜µ-å‘é‡ä¹˜è¿ç®—ï¼š
$$
A \mathbf{x}=\left[\begin{array}{cccc}
a_{11} & a_{12} & \ldots & a_{1 n} \\
a_{21} & a_{22} & \ldots & a_{2 n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m 1} & a_{m 2} & \ldots & a_{m n}
\end{array}\right]\left[\begin{array}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{n}
\end{array}\right]=\left[\begin{array}{c}
a_{11} x_{1}+a_{12} x_{2}+\cdots+a_{1 n} x_{n} \\
a_{21} x_{1}+a_{22} x_{2}+\cdots+a_{2 n} x_{n} \\
\vdots \\
a_{m 1} x_{1}+a_{m 2} x_{2}+\cdots+a_{m n} x_{n}
\end{array}\right]
$$

```python
>>> # batched matrix x broadcasted vector
>>> tensor1 = torch.randn(10, 3, 4)
>>> tensor2 = torch.randn(4)
>>> torch.matmul(tensor1, tensor2).size()
torch.Size([10, 3])
```

batched æ„æ€æ˜¯ tensor1 ç¬¬ä¸€ç»´çš„ 10 è¢«è§†ä¸º batchï¼Œç„¶å tensor2 å¯¹ batch è¿›è¡Œå¹¿æ’­åå˜ä¸º (10, 4)ï¼Œå®é™…æ˜¯ä¸€ä¸ª (3, 4) ä¸ (4) çš„çŸ©é˜µ-å‘é‡ä¹˜ã€‚

```python
>>> # batched matrix x batched matrix
>>> tensor1 = torch.randn(10, 3, 4)
>>> tensor2 = torch.randn(10, 4, 5)
>>> torch.matmul(tensor1, tensor2).size()
torch.Size([10, 3, 5])
```

å°† shape[0] ä¹Ÿå°±æ˜¯ 10 è§†ä¸º batchï¼Œå…¶ä½™éƒ¨åˆ†æ­£å¸¸åšçŸ©é˜µä¹˜ã€‚

```python
>>> # batched matrix x broadcasted matrix
>>> tensor1 = torch.randn(10, 3, 4)
>>> tensor2 = torch.randn(4, 5)
>>> torch.matmul(tensor1, tensor2).size()
torch.Size([10, 3, 5])
```
tensor2 å¯¹ batch è¿›è¡Œå¹¿æ’­ï¼Œç„¶åå…¶ä½™éƒ¨åˆ†æ­£å¸¸åšçŸ©é˜µä¹˜ã€‚

> numpy.matmul(x1, x2, /, out=None, *, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj, axes, axis])

Numpy ä¸­çš„ matmul ä¸ torch ä¸­ä¸€è‡´ã€‚

### bmm

åŠŸèƒ½å¦‚å…¶åï¼Œtorch ä¸ºäº†æ–¹ä¾¿æ‰¹å¤„ç†å¼ é‡ä¹˜è¿ç®—ï¼Œè¿˜ä¸“é—¨æä¾›äº† batch matrix-matrix product å‡½æ•°ã€‚

> torch.bmm(input, mat2, *, deterministic=False, out=None) â†’ Tensor

æ³¨æ„ bmm è¿™ä¸€æ‰¹å¤„ç†ä¸“ç”¨å‡½æ•°å¹¶ä¸æä¾›å¹¿æ’­æœºåˆ¶ï¼Œè¾“å…¥çš„ä¸¤ä¸ªå¼ é‡å¿…é¡»ä¸¥æ ¼æ˜¯ **3-D** çš„ã€‚

å½¢å¼åŒ–åœ°ï¼Œbmm åšè¿™æ ·çš„è¿ç®—ï¼š

å¦‚æœ```input```ä¸ºä¸€ä¸ªå½¢çŠ¶ä¸º (b, n, m) çš„å¼ é‡ï¼Œ```mat2``` æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º (b, m, p) çš„å¼ é‡, é‚£ä¹ˆ ```out``` åˆ™ä¼šæ˜¯ä¸€ä¸ª(b, n, p) çš„å¼ é‡ ã€‚

ä¹Ÿå°±æ˜¯å°† b è§†ä¸º batch ç»´åº¦ï¼Œå…¶ä½™ç»´åº¦è¿›è¡ŒäºŒç»´å¼ é‡ä¹˜ã€‚

### mv

åŠŸèƒ½å¦‚å…¶åï¼Œtorch ä¸­ä¸“é—¨è¿›è¡Œ matrix-vector product çš„å‡½æ•°ã€‚

> torch.mv(input, vec, *, out=None) â†’ Tensor

### mm

åŠŸèƒ½å¦‚å…¶åï¼Œtorch ä¸­ä¸“é—¨è¿›è¡Œ matrix multiplication çš„å‡½æ•°ã€‚

> torch.mm(input, mat2, *, out=None) â†’ Tensor

åŒæ ·åœ°ï¼Œè¯¥å‡½æ•°ç¦æ­¢å¹¿æ’­ã€‚

**ä¸ºäº†æé«˜ä»£ç çš„å¯è¯»æ€§å’Œé¿å…å‡ºé”™ï¼Œä½¿ç”¨ä¸“ç”¨å‡½æ•°è€Œé matmul æ˜¯å€¼å¾—æå€¡çš„ã€‚**


## multiply

> torch.mul(input,other, *, out=None) â†’ Tensor

**çŸ©é˜µ**ç‚¹ä¹˜ï¼Œå…¶è¿ç®—æ€§è´¨ä¸å‘é‡ç‚¹ä¹˜ä¸€è‡´ï¼Œä¹Ÿå°±æ˜¯**æŒ‰ä½ä¹˜**ï¼Œæ³¨æ„å½“ç»´åº¦ä¸åŒ¹é…æ—¶ï¼Œå¦‚æœç¬¦åˆå¹¿æ’­è§„åˆ™ï¼Œè¯¥å‡½æ•°è‡ªåŠ¨å¯¹å¼ é‡è¿›è¡Œå¹¿æ’­ã€‚

PyTorch å®˜ç½‘ä¸Šçš„ä¾‹å­å¹¶ä¸åˆé€‚ï¼Œåœ¨è¿™ç§æç«¯æƒ…å†µä¸‹ï¼ŒçŸ©é˜µæŒ‰ä½ä¹˜å’ŒçŸ©é˜µä¹˜æ˜¯ç­‰ä»·çš„ï¼š

```python
>>> a = torch.randn(4, 1)
>>> a
tensor([[ 1.1207],
        [-0.3137],
        [ 0.0700],
        [ 0.8378]])
>>> b = torch.randn(1, 4)
>>> b
tensor([[ 0.5146,  0.1216, -0.5244,  2.2382]])
>>> torch.mul(a, b)
tensor([[ 0.5767,  0.1363, -0.5877,  2.5083],
        [-0.1614, -0.0382,  0.1645, -0.7021],
        [ 0.0360,  0.0085, -0.0367,  0.1567],
        [ 0.4312,  0.1019, -0.4394,  1.8753]])
```
æ¢ä¸€ä¸ªä¾‹å­å°±å¾ˆæ˜äº†äº†ï¼š
```python
>>> a = torch.randn(1,4)
>>> a
tensor([[-0.4023,  1.2729,  1.4055, -1.4597]])
>>> b = torch.randn(4,1)
>>> b
tensor([[0.1225],
        [1.0653],
        [1.4184],
        [1.1043]])
>>> torch.mul(a, b)
tensor([[-0.0493,  0.1560,  0.1722, -0.1789],
        [-0.4285,  1.3561,  1.4973, -1.5550],
        [-0.5706,  1.8055,  1.9935, -2.0704],
        [-0.4442,  1.4056,  1.5520, -1.6119]])
```

æ˜¾ç„¶ï¼Œå¦‚æœæ˜¯çŸ©é˜µä¹˜ ```torch.matmul(a,b)```ï¼Œä¼šå¾—åˆ°ä¸€ä¸ª shape ä¸º (1) çš„æ ‡é‡ï¼Œåœ¨æŒ‰ä½ä¹˜æ—¶ï¼Œa çš„å½¢çŠ¶ (1, 4) è¢«å¹¿æ’­ä¸º (4, 4)ï¼Œb ä¹Ÿä¸€æ ·ï¼Œæœ€å (4, 4) ä¸ (4, 4) æŒ‰ä½ä¹˜ï¼Œå¾—åˆ° (4, 4) çš„å¼ é‡ã€‚

> numpy.multiply(x1, x2, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj])

Numpy ä¸­çš„ multiply ä¹Ÿå’Œ torch ä¸­ä¸€è‡´ã€‚

## æ—¶æ•ˆæ€§

- PyTorch==1.9.1
- Numpy==1.21

## å‚è€ƒ

https://numpy.org/doc/stable/user/theory.broadcasting.html

https://pytorch.org/docs/stable/generated/torch.matmul.html

https://mathinsight.org/matrix_vector_multiplication
